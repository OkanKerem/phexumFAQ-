{
  "name": "RetrievingSubFaq",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        940,
        180
      ],
      "id": "6ea78663-cf2f-4f2d-8e68-43047c2afd87",
      "name": "Embeddings OpenAI",
      "credentials": {
        "openAiApi": {
          "id": "JXw4mNQVGwKFtOgg",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "### Readme\nLoad your data into a vector database with the üìö **Load Data** flow, and then use your data as chat context with the üêï **Retriever** flow.\n\n**Quick start**\n1. Click on the `Execute Workflow` button to run the üìö **Load Data** flow.\n2. Click on `Open Chat` button to run the üêï **Retriever** flow. Then ask a question about content from your document(s)\n\n\nFor more info, check [our docs on RAG in n8n](https://docs.n8n.io/advanced-ai/rag-in-n8n/).",
        "height": 300,
        "width": 440,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -660,
        -60
      ],
      "typeVersion": 1,
      "id": "0d07742b-0b36-4c2e-990c-266cbe6e2d4d",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "### üìö Load Data Flow",
        "height": 460,
        "width": 700,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -940,
        180
      ],
      "typeVersion": 1,
      "id": "d19d04f3-5231-4e47-bed7-9f24a4a8f582",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        800,
        120
      ],
      "id": "b5aa8942-9cd5-4c2f-bd77-7a0ceb921bac",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "JXw4mNQVGwKFtOgg",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "### üêï 2. Retriever Flow",
        "height": 460,
        "width": 680,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        700,
        -160
      ],
      "typeVersion": 1,
      "id": "28bc73a1-e64a-47bf-ac1c-ffe644894ea5",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "### Embeddings\n\nThe Insert and Retrieve operation use the same embedding node.\n\nThis is to ensure that they are using the **exact same embeddings and settings**.\n\nDifferent embeddings might not work at all, or have unintended consequences.\n",
        "height": 240,
        "width": 320,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        660,
        440
      ],
      "typeVersion": 1,
      "id": "0cf8c647-418c-4d1a-8952-766145afca72",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Work with data ",
        "pineconeIndex": {
          "__rl": true,
          "value": "deneme",
          "mode": "list",
          "cachedResultName": "deneme"
        },
        "topK": 3,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        1100,
        100
      ],
      "id": "c892a652-ac1c-43cc-85e0-f9e865fcadd6",
      "name": "Pinecone Vector Store",
      "credentials": {
        "pineconeApi": {
          "id": "gyxGXSwdD8TK7seO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Sen sistem i√ßin bir m√º≈üteri hizmetleri yapay zekasƒ±sƒ±n bir dil √∂ƒürenim platformunda,sorular bir dil √∂ƒürenme platformuna g√∂re d√º≈ü√ºn,sana tool olarak verdiƒüim pinecode vector storeu kullan {{ $json.query }}",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2,
      "position": [
        1080,
        -100
      ],
      "id": "40a6b8be-eab4-48a2-8d0b-ae6bc8647fc2",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "query"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        800,
        -100
      ],
      "id": "f5dfe755-a2dd-42d6-bd8f-3a11a6a84106",
      "name": "When Executed by Another Workflow"
    }
  ],
  "pinData": {},
  "connections": {
    "Embeddings OpenAI": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ],
      "ai_vectorStore": [
        []
      ]
    },
    "AI Agent": {
      "main": [
        []
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "440ddca7-7577-46f2-8da3-b9608b62123e",
  "meta": {
    "templateId": "rag-starter-template",
    "templateCredsSetupCompleted": true,
    "instanceId": "33d3118021c86740b1a15c617d0d9d55d063df19d7374e00a1b8953c3734f20d"
  },
  "id": "aekjd5HoAjVh38fg",
  "tags": []
}